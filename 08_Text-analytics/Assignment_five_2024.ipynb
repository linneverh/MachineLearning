{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michalis0/MGT-502-Data-Science-and-Machine-Learning/blob/main/08_Text-analytics/Assignment_five_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZu-7QbP9muh"
      },
      "source": [
        "DSML investigation:\n",
        "\n",
        "You are part of the Suisse Impossible Mission Force, or SIMF for short. You need to uncover a rogue agent that is trying to steal sensitive information.\n",
        "\n",
        "Your mission, should you choose to accept it, is to find that agent before stealing any classified information. Good luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyL7WNdV9sWV"
      },
      "source": [
        "# Assignment part five\n",
        "\n",
        "More information came in that suggests that the rogue agent is tampering with the sentiment annotation system of the SIMF which analyses news documents and marks their sentiment for intelligence analysis tasks.\n",
        "\n",
        "This annotation is crucial to identify documents expressing negativity towards Switzerland and its allies.\n",
        "\n",
        "Each document contains a column which shows which user accessed it. We know that the rogue agent accessed only the documents whose negative sentiment was high, and was then changed to positive or neutral. We will use a huggingface model to identify which records have been tampered with.\n",
        "\n",
        "\n",
        "[You can find more models on this link](https://huggingface.co/models?sort=trending)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHhI95r5-tyD"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets transformers huggingface_hub\n",
        "!apt-get install git-lfs\n",
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U\n",
        "# Import required packages\n",
        "from transformers import pipeline, DataCollatorWithPadding\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "torch.cuda.is_available()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx8xYrO4CxL-"
      },
      "source": [
        "# 1. Getting to know our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGE_4cFOqxbg"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel('https://raw.githubusercontent.com/michalis0/MGT-502-Data-Science-and-Machine-Learning/main/data/Reduced_Set_2100.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fb3Onvokqxbh"
      },
      "outputs": [],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmH1uBydDB9b"
      },
      "source": [
        "# 2. Re-evaluating with SIMF's model:\n",
        "Evaluate the sentiment on the title column using a sentiment pipeline trained on the `finiteautomata/bertweet-base-sentiment-analysis`model\n",
        "\n",
        "\n",
        "_This may take a while_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3TGz8z4Dfh9"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_RlHub7zdml"
      },
      "source": [
        "## 2.1 How many of the total entries match both the SIMF model **and** the hugginface model?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The SIMF model values are found in the 'evaluation' column, while the hugginface model values should be found in the new column, which you added to the table in the previous step.\n",
        "\n",
        "Display:\n",
        "*   The rows/records with same sentiment for both models.\n",
        "*   The number of matching values.\n",
        "*   The share of matching values of the total number of values.\n",
        "\n"
      ],
      "metadata": {
        "id": "Qup5cwL79D4E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiNq8Ao-zdUh"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1.** How many documents have the same sentiment according to both models?"
      ],
      "metadata": {
        "id": "FrpDo55srrTs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7nH3eY5y82X"
      },
      "source": [
        "## 2.2 We will now focus on the entries that do not match\n",
        "#### Identify all non matching entries.\n",
        "Create a subset with all the entries that were evaluated differently by the two models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZfbRN8Y-O4V"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-XZXkjm1uzk"
      },
      "source": [
        "## 2.3 How many of those entries that our model predicted as negative, are evaluated as neutral or positive by the SIMF model ?\n",
        "\n",
        "Create a subset with only those values, which appear as 'positive' or 'neutral' in the original 'evaluation' column, but are marked as having a 'negative' sentiment by the new hugginface model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgZtQbdl19Ek"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2.** How many entries were changed from negative to neutral or positive?"
      ],
      "metadata": {
        "id": "J9WpRfTgsn6E"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKzgCDAq7_6O"
      },
      "source": [
        "# 3. Use the ChangeLog dataframe to identify the usersID's who edited the entries.\n",
        "\n",
        "Consider the subset you created in the previous step.\n",
        "\n",
        "By combining it with ChangeLog, display only those userIDs, that belong to the people who tried to mask the 'negative' sentiments by assigning these sentences a 'positive' or 'neutral' value.\n",
        "\n",
        "In other words, match the previous subset with corresponding UserIDs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjA97Cfv9g_j"
      },
      "outputs": [],
      "source": [
        "ChangeLog = pd.read_csv('https://raw.githubusercontent.com/michalis0/MGT-502-Data-Science-and-Machine-Learning/main/data/ChangeLogFix.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "m7-jmLjkUC1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3.** Which users are suspects according to your findings?"
      ],
      "metadata": {
        "id": "ZdaJ0lqhtJpl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3Zo8voPe-fP"
      },
      "source": [
        "# 4. Identifying important informations on the altered documents.\n",
        "\n",
        "In this section we will use the TF-IDF text representation model to identify other important information on the altered documents.\n",
        "\n",
        "The first step is to create a list with all the original texts found in the df."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a list of the text within articles\n",
        "corpus = df['news'].tolist()"
      ],
      "metadata": {
        "id": "C_OfWwzN_4yE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "# Using default tokenizer in TfidfVectorizer\n",
        "\n",
        "\n",
        "# Learn the vocabulary dictionary and return document-term matrix\n",
        "\n",
        "\n",
        "# Visualize result in dataframe\n"
      ],
      "metadata": {
        "id": "lTSH1vJRAGqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSPoVKNvTCIO"
      },
      "outputs": [],
      "source": [
        "# Assume altered_titles contains the titles of altered documents\n",
        "\n",
        "# Extract the text of the altered articles\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep the entries related to tampered documents\n",
        "\n",
        "# Identify the record that stands out the most on the altered documents (ou can use the sum of the tokenizers results)\n"
      ],
      "metadata": {
        "id": "Z5XjV3YFAPOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many records contain the word that is the most frequent across all the texts?\n",
        "# e.g. if the word that stood out the most was \"mouton\", how many of the altered records contain the word mouton.\n",
        "\n",
        "# How about the second word that stands out the most\n",
        "\n",
        "# How about the third ?\n",
        "\n",
        "# How about the fourth ?\n"
      ],
      "metadata": {
        "id": "8ep6xpyfATli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4:** What word appears the most according to its tokenization?\n",
        "\n",
        "**Question 5:** How many times did the most frequent word appear?\n",
        "\n",
        "**Question 6:** What word appears as second most used according to its tokenization?\n",
        "\n",
        "**Question 7:** How many times did the second most frequent word appear?"
      ],
      "metadata": {
        "id": "4SOTh6dPyaE3"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}