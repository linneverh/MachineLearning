{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michalis0/MGT-502-Data-Science-and-Machine-Learning/blob/main/Updated_Assignments/Assignment_4_2024_updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZu-7QbP9muh"
      },
      "source": [
        "DSML investigation:\n",
        "\n",
        "You are part of the Suisse Impossible Mission Force, or SIMF for short. You need to uncover a rogue agent that is trying to steal sensitive information.\n",
        "\n",
        "Your mission, should you choose to accept it, is to find that agent before stealing any classified information. Good luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyL7WNdV9sWV"
      },
      "source": [
        "# Assignement part four\n",
        "#### Identifying the suspects' credit score\n",
        "We received informations that the rogue agent has a good credit score.\n",
        "\n",
        "Our spies at SIMF have managed to collect financial information relating to our suspects as well as a training dataset.\n",
        "\n",
        "Create a Neural Network over the training dataset `df` to identify which of the suspects have a good Credit_Mix\n",
        "\n",
        "\n",
        "## Getting to know our data\n",
        "\n",
        "* Age: a users age\n",
        "* Occupation: a users employment field\n",
        "* Annual_Income: a users annual income\n",
        "* Monthly_Inh_Salary: the calculated salary received by a given user on a monthly basis\n",
        "* Num_Bank_Accounts: the number of bank accounts possessed by a given user\n",
        "* Num_Credit_Cards: the number of credit card given user possesses\n",
        "* Interest_Rate: The interest rate on those cards (if multiple then its the average)\n",
        "* Num_of_Loans: The number of loans of each user\n",
        "* Delay_from_due_date: payment tardiness of user\n",
        "* Num_of_Delayed_Payment: the count of delayed payments\n",
        "* Changed_Credit_Limit: changes made to the credit limit for each user's account\n",
        "* Num_Credit_Inquiries: number of credit inquiries\n",
        "* Credit_Mix: The users credit score\n",
        "* Outsting_Debt: Outstanding debt\n",
        "* Credit_Utilization_Ratio: the percentage of borrowed money over borrowing allowance\n",
        "* Payment_of_Min_Amount: does the user usually pay the minimal amount (categorical)\n",
        "* Total_EMI_per_month: Monthly repayments to be made\n",
        "* Amount_invested_monthly: The amout put in an investment fund by the user on a monthly basis\n",
        "* Payment_Behaviour: the users payment behavior (categorical)\n",
        "* Monthly_Balance: The users end of the month balance\n",
        "* AutoLoan: If the user has an active loan for their vehicule\n",
        "* Credit-BuilderLoan: If the user has a loan to increase their credit score\n",
        "* DebtConsolidationLoan, HomeEquityLoan, MortgageLoan, NotSpecified, PaydayLoan, PersonalLoan, StudentLoan: different types of loans(categorical features)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHhI95r5-tyD"
      },
      "outputs": [],
      "source": [
        "# Import required packages\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXm79UyPF1Bz"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/michalis0/MGT-502-Data-Science-and-Machine-Learning/main/data/train_classification.csv\", index_col='Unnamed: 0').dropna()\n",
        "suspects = pd.read_csv(\"https://raw.githubusercontent.com/michalis0/MGT-502-Data-Science-and-Machine-Learning/main/data/suspects.csv\", index_col='Unnamed: 0').dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHi25uhvF1Bz"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpZT59dqF1B0"
      },
      "outputs": [],
      "source": [
        "df[\"Credit_Mix\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZENObtyefVk"
      },
      "source": [
        "# 1. Preparing the data\n",
        "## 1.1 Data cleaning\n",
        " Perform One-Hot Encoding over the \"Occupation\" feature.\n",
        "\n",
        " Then, perform Label Encoding over \"Payment_of_Min_Amount\" and \"Payment_Behaviour\".\n",
        "\n",
        " After performing the one-hot and label encoding, add the encoded features to the data frame and remove the corresponding categorical features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGVrLNJTefVk"
      },
      "outputs": [],
      "source": [
        "# Your code here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfPnhUxAefVl"
      },
      "source": [
        "## 1.2 Dataset splitting and rescaling\n",
        "\n",
        "a) Split the dataset in two, first X with your independent features and then y with the dependent feature **CreditMix**.\n",
        "\n",
        "b) Split X and y into training and test sets. The training set should contain 80% of the observations, and the test set should contain the remaining 20%. Set random state equal to 42.\n",
        "\n",
        "c) Then perform :\n",
        "* Label Encoding over the **CreditMix** feature.\n",
        "* A MinMaxScaller over all the independent features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-mentarefVm"
      },
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmjXsvhKF1B3"
      },
      "source": [
        "### 1.2.2 Final touches\n",
        "Convert your datasets to `Torch tensors` of type `torch.float` for X and `torch.long` for y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KS_U8stefVo"
      },
      "outputs": [],
      "source": [
        "#Your code here:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpJNiQADF1B3"
      },
      "source": [
        "# 2 Model preparation:\n",
        "\n",
        "## 2.1 Define a Neural network model and instantiate it.\n",
        "Set the following parameters:\n",
        "* `hidden layer` : 1 with 150 nurons;\n",
        "* `activation function` : ReLU\n",
        "* `criterion` : [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cx-3yvp5efVp"
      },
      "outputs": [],
      "source": [
        "# Define the neural network class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bnfvHbEF1B4"
      },
      "source": [
        "## 2.2 Finding the best model:\n",
        "Identify, amongst the following options the best parameters for your model:\n",
        "\n",
        "* `criterion` : [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)\n",
        "* `iterations` : 150, 250, 500, 1000\n",
        "* `learning rate` : 0.00005, 0.001, 1.049, 12.031\n",
        "\n",
        "Set `random seed` as torch.manual_seed(42).\n",
        "\n",
        "\n",
        "_Hint: restart your runtime between each execution to ensure that previous neural networks dont interfere with your current one_\n",
        "\n",
        "_You can evaluate your model based on it's accuracy over the test set_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "6YlMyENrG3mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1. Could we use BCELoss instead of CrossEntropyLoss?**"
      ],
      "metadata": {
        "id": "rVn0_N37Lg2c"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMa1WScWF1B8"
      },
      "source": [
        "# 3. Predict over the suspects dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it's time to use the model to make predictions over the suspect dataset!\n",
        "\n",
        "Use the following parameters:\n",
        "\n",
        "\n",
        "* `hidden layer` : 1 with 150 neurons\n",
        "* `output layer` : 3 neurons\n",
        "* `optimizer` : [Stochastic Gradient Descent (SGD)](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)\n",
        "* `criterion` : [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)\n",
        "* `iterations` : 1000\n",
        "* `learning rate` : 1.049\n",
        "\n",
        "Set `random seed` as np.random.seed(42)\n",
        "\n"
      ],
      "metadata": {
        "id": "qxz8kefSHAqT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Question 2:*\n",
        "\n",
        "**Why does our model has 3 neurons in the output layer?**"
      ],
      "metadata": {
        "id": "O8diIPbsLrh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "kHwplnc1JECi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the table with two columns: 'userID' and the corresponding predicted Credit_Mix."
      ],
      "metadata": {
        "id": "k6hdN8ZOJMgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Your code here"
      ],
      "metadata": {
        "id": "PeIKEtZ8JKS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As mentioned in the beginning, we have reasons to believe that the suspect had a very good credit score. But we must make no errors, because a lot is at stake. We must be consident in our predictions.\n",
        "\n",
        "Therefore, we need to analyze not just the predicted category but also how certain the model is about each prediction. Display the probabilities of observations in the 'suspects' dataset falling within the given classes.\n",
        "\n",
        "_Hint: you can display the probabilities simply as a dataframe, but for better overview you can use visualization tools_"
      ],
      "metadata": {
        "id": "x4oGVP1hJaCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "fSL2d1K-KeKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Question 3:*\n",
        "\n",
        "**Which of the following suspects have a good credit mix according to your model's predictions?**\n",
        "\n",
        "\n",
        "*   200865\n",
        "*   761992\n",
        "*   858566\n",
        "*   862880\n",
        "*   526987\n"
      ],
      "metadata": {
        "id": "OK0J3mmALxUo"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}